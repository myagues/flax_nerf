{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny NeRF with Flax\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/myagues/flax_nerf/blob/main/tiny_nerf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This is a simplied version of the method presented in *NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis*, using Flax and supporting multiple device TPU or GPU training.\n",
    "\n",
    "Original work:\n",
    "- [Project Website](https://www.matthewtancik.com/nerf)\n",
    "- [arXiv Paper](https://arxiv.org/abs/2003.08934)\n",
    "- [Full Code](https://www.github.com/bmild/nerf)\n",
    "\n",
    "Components not included in the notebook:\n",
    "- 5D input including view directions\n",
    "- Hierarchical Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U flax jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import time\n",
    "\n",
    "import imageio\n",
    "import jax\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from flax import jax_utils, linen as nn, optim\n",
    "from flax.training import common_utils\n",
    "from jax import numpy as jnp, lax\n",
    "from jax.config import config\n",
    "from typing import Any, Callable, Sequence\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline\n",
    "\n",
    "config.enable_omnistaging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running on Colab with TPUs\n",
    "if \"COLAB_TPU_ADDR\" in os.environ:\n",
    "    import jax.tools.colab_tpu\n",
    "\n",
    "    jax.tools.colab_tpu.setup_tpu()\n",
    "\n",
    "print(jax.local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"tiny_nerf_data.npz\"):\n",
    "    !curl -O -L https://people.eecs.berkeley.edu/~bmild/nerf/tiny_nerf_data.npz\n",
    "\n",
    "data = np.load(\"tiny_nerf_data.npz\")\n",
    "images = data[\"images\"]\n",
    "poses = data[\"poses\"]\n",
    "focal = float(data[\"focal\"])\n",
    "_, img_h, img_w, _ = images.shape\n",
    "\n",
    "testimg, testpose = images[101], poses[101]\n",
    "images = images[:100, ..., :3]\n",
    "poses = poses[:100]\n",
    "\n",
    "print(f\"Images shape: {images.shape}\")\n",
    "print(f\"Poses shape: {poses.shape}\")\n",
    "print(f\"Focal value: {focal:.5f}\")\n",
    "\n",
    "plt.imshow(testimg)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize NeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rays(img_h, img_w, focal, c2w):\n",
    "    \"\"\"Generate ray matrices.\"\"\"\n",
    "    i, j = np.meshgrid(np.arange(img_w), np.arange(img_h), indexing=\"xy\")\n",
    "    dirs = np.stack(\n",
    "        [(i - img_w * 0.5) / focal, -(j - img_h * 0.5) / focal, -np.ones_like(i)], -1\n",
    "    )\n",
    "    rays_d = np.einsum(\"ijl,kl\", dirs, c2w[:3, :3])\n",
    "    rays_o = np.broadcast_to(c2w[:3, -1], rays_d.shape)\n",
    "    return np.stack([rays_o, rays_d])\n",
    "\n",
    "\n",
    "def render_rays(\n",
    "    net_fn,\n",
    "    rays,\n",
    "    near=2.0,\n",
    "    far=6.0,\n",
    "    num_samples=64,\n",
    "    batch_size=10000,\n",
    "    rng=None,\n",
    "):\n",
    "    rays_o, rays_d = rays\n",
    "    # Compute 3D query points\n",
    "    z_vals = np.linspace(near, far, num_samples)\n",
    "    z_shape = rays_o.shape[:-1] + (num_samples,)\n",
    "    if rng is not None:\n",
    "        z_vals += jax.random.uniform(rng, z_shape) * (far - near) / num_samples\n",
    "    pts = rays_o[..., None, :] + rays_d[..., None, :] * z_vals[..., :, None]\n",
    "\n",
    "    # Run network\n",
    "    raw = lax.map(net_fn, jnp.reshape(pts, [-1, batch_size, 3]))\n",
    "    raw = jnp.reshape(raw, pts.shape[:-1] + (4,))\n",
    "\n",
    "    # Compute opacities and colors\n",
    "    sigma_a = nn.relu(raw[..., 3])\n",
    "    rgb = nn.sigmoid(raw[..., :3])\n",
    "\n",
    "    # Do volume rendering\n",
    "    dists = z_vals[..., 1:] - z_vals[..., :-1]\n",
    "    dists = jnp.concatenate(\n",
    "        [dists, np.broadcast_to([1e10], dists[..., :1].shape)], axis=-1\n",
    "    )\n",
    "\n",
    "    alpha = 1.0 - jnp.exp(-sigma_a * dists)\n",
    "    alpha_ = jnp.clip(1.0 - alpha, 1e-10, 1.0)\n",
    "    trans = jnp.concatenate([jnp.ones_like(alpha_[..., :1]), alpha_[..., :-1]], -1)\n",
    "    weights = alpha * jnp.cumprod(trans, -1)  # (img_h, img_w, num_samples)\n",
    "\n",
    "    rgb_map = jnp.einsum(\"...k,...kl\", weights, rgb)\n",
    "    depth_map = jnp.einsum(\"...k,...k\", weights, z_vals)\n",
    "    acc_map = jnp.einsum(\"...k->...\", weights)\n",
    "\n",
    "    return rgb_map, depth_map, acc_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to increase `num_samples` for better quality, out of memory (OOM) errors can appear when using TPUs (TPUv2 in Colab has 8GB of HBM memory per core, whereas GPUs range from 12GB to 16GB), as they use a padding mechanism (read the [TPU performance guide](https://cloud.google.com/tpu/docs/performance-guide#consequences_of_tiling) for more information). To work around these limitations, you can:\n",
    "- reduce `net_width` and / or `net_depth` (worse results)\n",
    "- enable `nn.remat` decorator (slower time per step). More about `jax.remat` in [JAX #1749](https://github.com/google/jax/pull/1749)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeRF(nn.Module):\n",
    "    net_depth: int = 8\n",
    "    net_width: int = 256\n",
    "    skips: Sequence[int] = (4,)\n",
    "    periodic_fns: Sequence[Callable] = (jnp.sin, jnp.cos)\n",
    "    out_channels: int = 4\n",
    "    use_embedding: bool = True\n",
    "    l_embed: int = 6\n",
    "    dtype: Any = jnp.float32\n",
    "    precision: Any = lax.Precision.DEFAULT\n",
    "\n",
    "    def embed(self, inputs):\n",
    "        batch_size, _ = inputs.shape\n",
    "        inputs_freq = jax.vmap(lambda x: inputs * 2.0 ** x)(jnp.arange(self.l_embed))\n",
    "        fns = jnp.stack([fn(inputs_freq) for fn in self.periodic_fns])\n",
    "        fns = fns.swapaxes(0, 2).reshape([batch_size, -1])\n",
    "        fns = jnp.concatenate([inputs, fns], axis=-1)\n",
    "        return fns\n",
    "\n",
    "    # @nn.remat\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs_pts):\n",
    "        x = self.embed(inputs_pts) if self.use_embedding else inputs_pts\n",
    "        for i in range(self.net_depth):\n",
    "            x = nn.Dense(self.net_width, dtype=self.dtype, precision=self.precision)(x)\n",
    "            x = nn.relu(x)\n",
    "            if i in self.skips:\n",
    "                x = jnp.concatenate([x, inputs_pts], axis=-1)\n",
    "        x = nn.Dense(self.out_channels, dtype=self.dtype, precision=self.precision)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def initialized(key, input_pts_shape):\n",
    "    model = NeRF()\n",
    "    initial_params = jax.jit(model.init)(\n",
    "        {\"params\": key},\n",
    "        jnp.ones(input_pts_shape),\n",
    "    )\n",
    "    return model, initial_params[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(opt, batch, rng):\n",
    "    \"\"\"Train step.\"\"\"\n",
    "    inputs, targets = batch\n",
    "\n",
    "    def loss_fn(params):\n",
    "        model_fn = lambda x: model.apply({\"params\": params}, x)\n",
    "        rgb, *_ = render_rays(model_fn, inputs, rng=rng)\n",
    "        return jnp.mean((rgb - targets) ** 2)\n",
    "\n",
    "    grads = jax.grad(loss_fn)(opt.target)\n",
    "    grads = lax.pmean(grads, axis_name=\"batch\")\n",
    "    new_opt = opt.apply_gradient(grads)\n",
    "    return new_opt\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def evaluate(params):\n",
    "    \"\"\"Evaluation step w/ PSNR metric.\"\"\"\n",
    "    model_fn = lambda x: model.apply({\"params\": params}, x)\n",
    "    rgb, *_ = render_rays(model_fn, test_rays)\n",
    "    loss = jnp.mean((rgb - testimg) ** 2)\n",
    "    psnr = -10.0 * jnp.log(loss) / jnp.log(10.0)\n",
    "    return rgb, psnr\n",
    "\n",
    "\n",
    "p_update = jax.pmap(update, axis_name=\"batch\")\n",
    "\n",
    "train_rays = np.stack(list(map(lambda x: get_rays(img_h, img_w, focal, x), poses)))\n",
    "test_rays = get_rays(img_h, img_w, focal, testpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_devices = jax.local_device_count()\n",
    "key, rng = jax.random.split(jax.random.PRNGKey(0))\n",
    "\n",
    "model, params = initialized(key, (10000, 3))\n",
    "optimizer = optim.Adam(learning_rate=5e-4).create(params)\n",
    "optimizer = jax_utils.replicate(optimizer)\n",
    "\n",
    "psnrs = []\n",
    "num_iters = 1000\n",
    "i_plot = 50\n",
    "\n",
    "for step in range(num_iters + 1):\n",
    "    t = time.time()\n",
    "    rng_idx, rng_step = jax.random.split(jax.random.fold_in(rng, step))\n",
    "    sharded_rngs = common_utils.shard_prng_key(rng_step)\n",
    "\n",
    "    idx = jax.random.randint(rng_idx, (n_devices,), minval=0, maxval=len(train_rays))\n",
    "    batch = train_rays[tuple(idx), ...], images[tuple(idx), ...]\n",
    "    optimizer = p_update(optimizer, batch, sharded_rngs)\n",
    "\n",
    "    if step % i_plot == 0:\n",
    "        t_end = time.time() - t\n",
    "        optimizer_ = jax_utils.unreplicate(optimizer)\n",
    "        rgb, psnr = evaluate(optimizer_.target)\n",
    "        print(f\"Iters: {step:4d}\\t{t_end:2.5f} sec/iter\\tPSNR: {psnr:.5f}\")\n",
    "        psnrs.append(np.asarray(psnr))\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "        ax1.imshow(rgb)\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.plot(np.arange(0, step + 1, i_plot), psnrs)\n",
    "        plt.show()\n",
    "\n",
    "optimizer = jax_utils.unreplicate(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_t = lambda t: np.asarray(\n",
    "    [\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 1, t],\n",
    "        [0, 0, 0, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "rot_phi = lambda phi: np.asarray(\n",
    "    [\n",
    "        [1, 0, 0, 0],\n",
    "        [0, np.cos(phi), -np.sin(phi), 0],\n",
    "        [0, np.sin(phi), np.cos(phi), 0],\n",
    "        [0, 0, 0, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "rot_theta = lambda th: np.asarray(\n",
    "    [\n",
    "        [np.cos(th), 0, -np.sin(th), 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [np.sin(th), 0, np.cos(th), 0],\n",
    "        [0, 0, 0, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def pose_spherical(theta, phi, radius):\n",
    "    c2w = trans_t(radius)\n",
    "    c2w = rot_phi(phi / 180.0 * np.pi) @ c2w\n",
    "    c2w = rot_theta(theta / 180.0 * np.pi) @ c2w\n",
    "    c2w = np.array([[-1, 0, 0, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0, 0, 0, 1]]) @ c2w\n",
    "    return c2w\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def get_rgb(rays):\n",
    "    model_fn = lambda x: model.apply({\"params\": optimizer.target}, x)\n",
    "    rgb, depth, acc = render_rays(model_fn, rays)\n",
    "    img = (255 * jnp.clip(rgb, 0, 1)).astype(jnp.uint8)\n",
    "    return img, depth, acc\n",
    "\n",
    "\n",
    "def f(**kwargs) -> None:\n",
    "    c2w = pose_spherical(**kwargs)\n",
    "    rays = get_rays(img_h, img_w, focal, c2w[:3, :4])\n",
    "    img, *_ = get_rgb(rays)\n",
    "\n",
    "    plt.figure(2, figsize=(20, 6))\n",
    "    plt.imshow(np.asarray(img))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "sldr = lambda v, mi, ma: widgets.FloatSlider(value=v, min=mi, max=ma, step=0.01)\n",
    "\n",
    "names = [\n",
    "    [\"theta\", [100.0, 0.0, 360]],\n",
    "    [\"phi\", [-30.0, -90, 0]],\n",
    "    [\"radius\", [4.0, 3.0, 5.0]],\n",
    "]\n",
    "\n",
    "interactive_plot = widgets.interactive(f, **{s[0]: sldr(*s[1]) for s in names})\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = \"475px\"\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render 360 Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_angle = jnp.linspace(0.0, 360.0, 120, endpoint=False)\n",
    "v_c2w = map(lambda th: pose_spherical(th, -30.0, 4.0), video_angle)\n",
    "rays = np.stack(list(map(lambda x: get_rays(img_h, img_w, focal, x[:3, :4]), v_c2w)))\n",
    "frames, *_ = lax.map(get_rgb, rays)\n",
    "frames = map(np.asarray, frames)\n",
    "\n",
    "file_name = \"video.mp4\"\n",
    "imageio.mimwrite(file_name, tuple(frames), fps=30, quality=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%HTML\n",
    "# <video width=\"500\" controls autoplay loop>\n",
    "#   <source src=\"video.mp4\" type=\"video/mp4\">\n",
    "# </video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "mp4 = open(\"video.mp4\", \"rb\").read()\n",
    "data_url = f\"data:video/mp4;base64,{b64encode(mp4).decode()}\"\n",
    "HTML(\n",
    "    \"\"\"\n",
    "<video width=500 controls autoplay loop>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\"\n",
    "    % data_url\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
